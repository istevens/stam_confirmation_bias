Style guide
===========

- Probability = chance or odds
- Hypothesis, theory = belief

https://en.wikipedia.org/wiki/Truthiness
https://today.yougov.com/news/2016/12/27/belief-conspiracies-largely-depends-political-iden/

Intro
=====

what it is,
why we should care,
how it grows and sticks with us,
why it develops, and
how to fight back.

What it is
==========

.. Need a snappier intro to draw reader in

Confirmation bias is one of many cognitive biases which affect how we reason.
Unlike a leaning or a slant, like left- or right-wing bias, cognitive biases
are the result of involuntary mental "short-cuts". [Brief example] These
short-cuts may have helped our ancestors quickly tell a friend from a foe, but
they impede logic and accuracy necessary in our modern world. [NELSON2015]_

While there are many cognitive biases, confirmation bias likely does us the
most harm. It leads us to hold false beliefs with a confidence greater than
evidence can justify. [NICKERSON1998]_ Those affected will often misinterpret
new information as supporting a previously-held belief. [RABIN1999]_ In this
way, confirmation bias tricks us into accepting untruths and nurtures them
until we are certain they are true.

Before confirmation bias had a name, people were thought to be largely
rational. Any errors in judgment were often blamed on weak
reasoning. [LARRICK2004]_ In his recount of the Peloponnesian War, Thucydides
(460BC-395BC) called confirmation bias a "habit"::

    "… for it is a habit of mankind to entrust to careless hope what they long
    for, and to use sovereign reason to thrust aside what they do not fancy.

Sir Francis Bacon (1561-1626) was more inclined to treat confirmation bias as a
trick of the mind::

    "The human understanding when it has once adopted an opinion (either as
    being the received opinion or as being agreeable to itself) draws all
    things else to support and agree with it."

It wasn't until 1960, when psychologist Peter Wason performed his first
selection experiment, that confirmation bias was studied and named.

Wason's experiment was simple: present a subject with three numbers (ie.
2-4-6), and ask him/her to identify a rule for the three numbers. The subjects
were then asked to pick three other numbers which fit their supposed rule, and
were told whether their numbers fit the actual rule. Although the actual rule
was "any ascending sequence", subjects would often come up with rules specific
to the initial triplet (eg. "numbers increasing by two") and would often only
pick triplets which confirmed their rule, never triplets which would show it
to be wrong. As we will learn later, improper selection of evidence is one
tendency which contributes to confirmation bias.

Since Wason's experiment, many studies have shown that not only do we hold
systematic biases, they are robust to corrective measures. [LARRICK2004]_ We as
individuals are largely unaware of our own confirmation bias. Worse, although
our reasoning about information is sometimes subject to bias, supporting
existing beliefs, we rationally apply that information to our own state of the
world. Ignorant to our own bias, further reasoning with our beliefs is
tainted. While our bias-influenced reasoning may be internally coherent, it
results in sub-optimal decisions. As we are unaware we are holding a
biased view of the world yet feel we are being rational, we can become
over-confident in our beliefs, and further reinforce our bias. [JONES2000]_
[RABIN1999]_


Why we should care
==================

As we'll learn later, confirmation bias can change the way we view
reality. Once affected, we may only see what we are led to expect. We may also
overvalue information or events which support our theories. Horoscopes are a
mild example of how these tendencies can be used and remain popular because of
them. People often feel that universally positive traits apply to themselves
without considering how widespread those traits actually are. This opens us to
believe and place faith in horoscopes, but also psychics, mind readers, and
other con artists. We often want to believe such people, often focusing on
when they right, not instances when they are wrong. [NICKERSON1998]_

Belief in horoscopes, clairvoyants, and mentalists are mild influences of
confirmation bias. The same tendency to see or remember what we expect or
desire can also feed more serious conditions such as hypochondria and paranoia.
Depressed people may also focus on information which strengthens their
depression, and ignore more positive information which may help them. [NICKERSON1998]_

Of greater concern is how confirmation bias can uphold stereotypes and
prejudice. Our tendency to see what we are led to expect can be detrimental to
what we think of other people or groups. Selective memory of events which
confirm our thinking means that unusual behaviour from distinct groups is more
readily recalled. Several studies have shown how bias can sway how we react
to people about whom we hold stereotypes — even if we are only told those
people belong to a specific group. [NICKERSON1998]_

In one such study, subjects were shown a video of a girl playing. Half the
subjects were told the girl's parents were college-educated who held
white-collar jobs. These subjects were shown the girl playing in a well-to-do
suburban neighbourhood. The other subjects were told the girl's parents were
high-school graduates who held blue-collar jobs, and were shown the girl
playing in a poor inner-city neighbourhood. Half the subjects in each
group were then asked to evaluate the girl's reading level after viewing an
identical video of her answering a series of questions. The group which was
told the girl was from a well-to-do suburban family rated her reading level
significantly higher than the group which was told she was from the inner-city. [RABIN1999]_

This biased tendency to judge based on stereotype doesn't come about after
years of prejudicial thinking either. In a study similar to the one above, 5-7
year-olds were told of a person who was "really, really smart." The children
were then shown a picture of four adults — two women and two men — and asked to
pick the "really, really smart" one. At aged 5, boys and girls chose their
own gender roughly equally. Girls aged 6 or 7, however, were significantly less
likely than boys the same age to view their own gender positively. In another
study with different children, boys and girls aged 6 or 7 were asked to comment
on a game for "really, really smart" children or one for children who "try
really, really hard." The girls were significantly less interested than the
boys in the games for smart children. [BIAN2017]_

Reading these studies, we may feel that are "smarter", that our reasoning is
stronger than others', and that we would not misjudge people, especially a
child, so readily. Yet people well-versed in reasoning and statistics can still
have a problem with confirmation bias. Numerous peer-reviewed studies claim to
show that women are less likely than men to take on risk. However, a 2013
"study of studies" claims that these studies and their authors are likely to be
affected by stereotypes induced by bias. [NELSON2015]_ The studies' authors
reached inaccurate conclusions by falling prey to a number of tendencies behind
confirmation bias.

Some studies on risk and gender reinforce existing gender stereotypes by
inaccurately citing conclusions of earlier literature, or emphasizing results
agreeing with stereotypes, while downplaying or not reporting results which
do not. These confirming results are, in turn, more likely to be published. In
other studies, confounding variables (some due to socialization and pressure to
conform to gender expectations) were neglected. In others, areas where women
naturally take on a great deal of risk (such as with child birth, and risk of
domestic violence) were neglected. Instead, other areas of risk (such as
finance) were studied and findings extrapolated to a broader context.
[NELSON2015]_ In the following paragraphs, we'll learn how tendencies such as
overweighing instances of positive confirmation cause confirmation bias to grow
and persist. Because we often pair these tendencies with internally coherent
patterns of reasoning, few are immune.


Why it develops and persists
============================

Confirmation bias can affect us all, but it doesn't happen by itself. It needs
agreeable conditions to grow, flourish, and persist. Several tendencies can
introduce bias as we develop our belief, while leaving our learning process
intact. All stages of belief development are affected, from our initial
hypothesis generation, to searching for, testing, interpreting, and recalling
evidence. [KLAYMAN1995]_

Sometimes we form a belief from weak evidence, and this is where confirmation
bias can start to take hold. This isn't to say that bias only occurs when
evidence of a belief is not ideal. That first formation of belief, however, is
very powerful, largely due to something called the primacy effect. Information
acquired early carries more weight and is more easily recalled. Belief will
then start to coalesce around those first pieces of information. With belief
backed by initial weak evidence, we will have problems correctly interpreting
better, possibly contradictory information received later. [RABIN1999]_ We
are more likely to question information which conflicts with existing beliefs
than that which agrees with our beliefs. [NICKERSON1998]_ That initial belief,
then, is very important as it is more likely to stick with us and will be
difficult to correct.

Evidence search/selection vs. interpretation
--------------------------------------------

Once we start to form a belief from initial evidence, we will often gather more
data. While we feel that we gather impartial evidence and adjust our belief
accordingly, this is likely not the case. Determining the likelihood our belief
is true based on other beliefs, each with their own odds of being true, can be
a complex task, and we often fail at it. [#bayes]_ For one, we often prefer positive
tests for belief which can confirm that belief but will not uncover false
negatives. [KLAYMAN1995]_ With Wason's 2-4-6 task as an example, subjects
picked three numbers which fit their theory in order to test it, not
three numbers which would fit a different but also valid theory, or do not fit
the theory at all.

.. [#bayes] Also known as Bayes' Theorem, this involves calculating the odds
   of an event occurring based on conditions related to the event.

This tendency to seek only positive evidence to match a theory uncovers
patterns which may not exist, as with Wason's 2-4-6 task, but also limits
discovery. In testing evidence, we tend to ask questions whose answer is "yes" if
the hypothesis is true. For instance, in one study on test selection, participants were given
a profile of an extrovert or an introvert and were asked to interview people to
determine if they fit that type. The questions participants picked were seen as
strongly confirming the personality type under test if given a positive answer,
and strongly disconfirming the type if given a negative answer. [NICKERSON1998]_
This reinforcement of our initial belief through positive tests leads us to be
more confident in our belief, even if the data we collect is inconclusive. [KLAYMAN1995]_

Any selectively collected evidence is then interpreted. Our confirmation bias
kicks in here as well, especially where the evidence is ambiguous or vague. In
instances where evidence is open to interpretation, we tend to give our beliefs
the benefit of the doubt. [KLAYMAN1995]_ As an example, a teacher might
interpret a student's non-standard answer to a question as either stupid or
creative, depending on how the teacher feels about the student beforehand.

We are also prone to view confirming evidence as reliable and relevant, and often
accept it at face value. Disconfirming evidence, however, is often seen as
unreliable and unimportant, and is scrutinized, often hypercritically,
especially if the source is believed to be subject to error. [RABIN1999]_
[KLAYMAN1995]_ Because of this, we generally require less confirming evidence
to uphold a belief than we do disconfirming evidence to reject one. This
largely depends on our degree of confidence in our belief and the value of
making a correct conclusion. However, our motivation for truth
may be outweighed by our need for self esteem, approval from others, control,
and internal consistency that confirming evidence may provide. [NICKERSON1998]_
In many cases, it may be more imporant for us to maintain our belief preference
than to be accurate. Being wrong can be painful and is often seen as undesirable.
We're also told to "have the courage of one's convictions." [KLAYMAN1995]_
Interpreting evidence, then, can be an internal fight between what is right and
what feels good.


Restricting attention to a favoured belief
------------------------------------------

Preferring evidence which supports belief
-----------------------------------------

Overweighing confirming evidence of belief
------------------------------------------

Seeing what one is seeking (self-fulfilling prophecies, or illusory correlation)
--------------------------------------------------------------------------------

Primacy effect
--------------


Does learning truly converge on optimizing behaviour?

Notes below highlights only, refer to written notes

.. notes
    JONES2000::
        - psychologists: reasoning subject to positive confirmation bias
            - ie. test of belief tends to search for confirming evidence, not disconfirming evidence [Becker1963]
            - eg. Wason 1968 with vowel => even # on reverse
            - cite study
        # despite cost to acquire info, strong evidence of positive conf in info acquisition
        # info interpreted as confirming hypothesis increases subject's confidence in its truth
            - even if information has no value
                => positive confirmation not simple error, but internally coherent pattern of reasoning
        # positive confirmation may have a considerable degree of robustness to experience
            - ppl learn value of looking for disconfirming evidence but seek confirmations with no info value

    KLAYMAN1995::
        # search for evidence
            - positive test strategies (eg. Wason 2-4-6) do not uncover false negatives
            - subjects confident based on inconclusive data
            - pref for extremity (want info on highly likely/unlikely features)
            - pref for tests which better distinguish alternatives (eg. prefer A or B)?
            - bias potential exists only if one fails to appreciate consequences
                - blind spot OK so long as one knows
        # interpretation of evidence
            - ambiguous evidence (vague, open to interpretation)
                - ppl tend to give hyp benefit of doubt, eg. brand loyalty
            - discount disconfirming evidence esp if data believed to be subject to error (Gorman1981)
                - fake news?
            - feature-positive effects
            - overweight confirming and pseudodiagnostic evidence
            - Bayes' law not widely understood
                - ppl believe p(D|H) alone good enough
                - eg. actions taken, not actions not taken
        - motivation to maintain self esteem and others' view of self
            - be accurate vs. belief preference
                - need more evidence to give up existing hyp than if neutral
            - painful to challenge
                - bad to be wrong
                - courage of one's convictions

    RABIN1999::
        - ppl who form initial hyp from weak evidence
            - have difficulty correctly interpreting subsequent, better info which contradicts
                - due to propensity to recall strengths of confirming, weaknesses of disconfirming
                - due to tendency to judge confirming evidence as reliable and relevant, disconfirming as opposite
                - due to accepting confirming evidence at face value and scrutinizing disconfirming evidence hypercritically
        - contributions:
            # interpret ambigious evidence (unlike visual tasks) => CB and overconfidence
                - need degree of abstraction
                - eg. teacher interpreting student as having creative or stupid answers
            # when ppl must interpret statistical evidence for correlation
                - ppl often imagine correlation between events if no correlation exists (eg. sugar => hyperactivity)
                - ppl underestimate correlation if hold no existing theory
                    - and exaggerate correlation if preconceived theory
            # when ppl selectively collect or scrutinize evidence
                - ppl tend to ask questions likely to be true if theory is true
                  without considering if likely to be true even if hyp is false

    NELSON2013::
        - may take only one observation of a difference to add a new "essential" characteristic to a group
        - drive to essentialize to strong that
          generic statements => universal, individual memmbers of class [Khemlani 2009]
        - misinterpretation of stats results somewhat due to tendency to [Bakan 1966]
            - go from sample results in sample aggregate to inferences on population aggregate (Fisherian unfoundedness)o               - eg. "X are more Y than Z" from "statistically significant difference in mean Y"

    NICKERSON1998::
        # restrict attention of favored hypothesis (even if other opposing beliefs known)
            - p(D|H) vs. p(D|~H)
            - ppl do not consider pseudodiagnosticity
        # preferential treatment of evidence supporting hypothesis
            - give greater weight to favoured hyp
            - fail to recall or produce reasons for competing side
            - have belief as we can think of/recall more reasons to support
            - more likely to rate one-sided arguments higher than two-sided arguments
        # seeking only or mostly positive cases
            - find patterns where they are not
            - selective testing
                - test hyp on examples as if hyp already correct
                - no discovery
                - eg. Wason 2-4-6
                - tie into test cases written after code?
                - tend to ask questions whose answer is yes if hyp true
                    - eg. extrovert/introvert
        # seeing what one is looking for
            - askers see answers supportive of hyp
            - answerers influenced by interviewer
            - expectation guided change vs. expectation-interpreted belief
                - eg. low/high-class student with identical tape
            - seeing or remembering expected behaviour
            - belief that 2 vars related
                => increase chances of locating confirming evidence
                => decrease chancees of locating disconfirming evidence
                - illusory correlation
        # overweighing positive confirmatory instances
            - ppl generally require less hyp-consistent evidence to accept
              than hyp-inconsistent evidence to reject
            - depends on degree of confidence and importance of drawing correct conclusion
            - FACTORS: needs for self esteem, control, and cognitive consistency
            # selective attention to what is true, ignore/discount what is not
            # consider only P(D|H), not P(D|~H) (eg. gamblers explain away losses)
            - people fail to apply contrapositive
            - ppl believe P=>Q ~ Q=>P or ~ iff P=>
            - ppl check if consequent is true when antecedent is true
        # primacy effect - info acquired early carries more weight
            - eg. blurry slides of Bruner 1964
            - ppl more likely to question info conflicting pre-existing belief
              than info consistent with pre-existing belief
            - ppl more likely to see ambiguous info as confirming hyp than disconfirming it
                => 2 ppl can see opposing opinion in same info
                - and explain away events inconsistent with prior belief
            - ppl find it easy to stick with beliefs formed with faluse info even after info shown to be false [ROSS82]
                - fake news

    LARRICK2004::
        - ppl have basic stats/logic/econ knowledge but may not know how and when to apply
        - ppl reason more accurately about frequency than probability
            - eg. Bayes


References
==========

.. [BIAN2017] Bian, L., Leslie, S., and Cimpian, A. (2017). Gender stereotypes
   about intellectual ability emerge early and influence children’s interests.
   Science, 27 Jan 2017, Vol. 355, Issue 6323, pp. 389-391.

.. [JONES2000] Jones, M., and Sugden, R. (2000). Positive confirmation bias in
   the acquisition of information. (Dundee Discussion Papers in Economics; No.
   115). University of Dundee.

.. [KLAYMAN1995] Klayman, J. (1995). Varieties of confirmation bias. In J.
   Busemeyer, R. Hastie, & D. L. Medin (Eds.), Decision making from a cognitive
   perspective. New York: Academic Press (Psychology of Learning and Motivation,
   vol. 32), pp. 365-418.

.. [LARRICK2004] Larrick, R. P. (2004) Debiasing, in Blackwell Handbook of
   Judgment and Decision Making (eds D. J. Koehler and N. Harvey), Blackwell
   Publishing Ltd, Malden, MA, USA.

.. [NELSON2015] Nelson, J. A. (2015), Are women really more risk-averse than
   men? A re-analysis of the literature using expanded methods. Journal of
   Economic Surveys, 29: 566-585.

.. [NICKERSON1998] Nickerson, J. S. (1998). Confirmation bias: a ubiquitous
   phenomenon in many guises. Review of General Psychology, Vol. 2, No. 2, pp.
   175-220.

.. [RABIN1999] Rabin, Matthew and Schrag, Joel L., (1999), First Impressions
   Matter: A Model of Confirmatory Bias, The Quarterly Journal of Economics, 114,
   issue 1, p. 37-82
