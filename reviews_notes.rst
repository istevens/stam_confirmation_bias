Preamble
========

Kofi, a nurse in a maternity ward, tells his friends that more babies are born
during a full moon. "Why, just last week it was crazy busy and I look outside
to see — sure enough — a full moon!" Kofi doesn't notice that during the next
full moon the ward is quiet.

As a child, Lee lived outside of London, England. Her father had it in for
the Welsh, and Lee grew to share his views. "They're always trouble, can't trust
'em," she says to a co-worker, Bill. Bill points out that two respected members
of their team are from Wales, but Lee is dismissive. "They're the good ones,
not like the others," she says.


What it is
==========

Rabin 1999::
    - ppl have cognitive bias that leads them to misinterpret new info as
      supporting previously held beliefs
    - induces overconfidence

Nelson 2013::
    - cognitive short cuts
    - required to quickly sort potentially dangerous from benign (class things into kinds)
    - OK for survival but not for logic and accuracy
    - p27 has cites

Nickerson 1998::
    - inappropriate bolstering of beliefs whose truth is in question
    - impartial evaluation vs. "building a case" (deliberate, see slant above)
    - deliberate vs. unwitting (where conf bias falls)
    - motivated (by desire to defend beliefs) vs. unmotivated (no personal interest, CB can still exist)
    - ppl prone to treat evidence in biased ways if issue at hand matters to them
    - many beliefs may be held with a strength or degree of certainty which exceeds what evidence justifies

Larrick 2004::
    - prior (esp economists and philosophers): ppl rational and errors due to
      improper empirical methods (Stanovich 1999)
    - now (esp decision researchers): systematic biases exist and are robust to corrective measures

Rabin 1999::
    - economists assumed ppl begin with subjective beliefs over different
      states of the world and use Bayes' Rule to update beliefs
    - reality: unaware of misreading but updated rationally

Jones 2000::
    - economics assumes agents are rational optimizers through repeated experience and optimization
    - psychologists: reasoning subject to positive confirmation bias

    Bias results in pattern of reasoning
        - leads to sub-optional decisions
        - internally coherent
        - self-reinforcing

Nickerson 1998::
    - ppl find it easy to stick with beliefs formed with false info even after info shown to be fictious [Ross 1982]

Klayman 1995::
    - ambiguity supports biased hypothesis
    - limited resources for all cognitive tasks => easiest course of action
    - bias towards the positive => cognitive failure [Evans 1989]
        eg. positive correlations between cues easier to learn [Klayman 1988]


Why we should care
==================

Rabin 1999::
    - teachers misread pupils performance as supporting initial impressions (inner city exper. p.8)
    - cite above study
    - ppl supporting prior sterotypes
Nelson 2013::
    - "smart people" still have problems with CB
    - cite this study specifically, summarise
    - "women are more risk averse than men" claim from studies
        - finding confirms popular stereotype as men as brave and adventurous
            - but what if affected by CB
Bian 2017::
    - tie with above
    - At 5, both boys and girls associated brilliance with their own gender to a similar extent
    - Girls aged 6-7 were significantly less likely to associate brilliance with their own gender
    - Leading girls to be less interested in games labelled for "really, really smart" children
    - YET girls disassociate brilliance with school smarts
Nickerson 1998::
    - perceptions are influenced by seeing what we are led to expect (with
      example of horoscopes)
    - seeing or remembering behaviour we expect feeds
        - stereotypes, prejudice, hypochondria, paranoia
    - depressed ppl focus on info which strengthens depression and ignore more
      positive info [Beck 78]
    - also brand identity [Chernev 97]
    - stereotyping (eg. specific behaviours more common with some groups)
        - illusory correlation
        - unusual behaviours in distinct group more readily recalled
    - overweighing positive instances
        - open to exploitation, eg. mind reader, horoscopes, psychics, gamblers
        - ppl believe universally positive traits apply to themselves
        - will focus on these rather than what doesn't because they want to believe
        - will not consider universality
        - draw from experience with friends
        - will strengthen belief, leading to overconfidence


How it grows and sticks with us
===============================

Notes below highlights only, refer to written notes

JONES2000::
    - psychologists: reasoning subject to positive confirmation bias
        - ie. test of belief tends to search for confirming evidence, not disconfirming evidence [Becker1963]
        - eg. Wason 1968 with vowel => even # on reverse
        - cite study
    # despite cost to acquire info, strong evidence of positive conf in info acquisition
    # info interpreted as confirming hypothesis increases subject's confidence in its truth
        - even if information has no value
            => positive confirmation not simple error, but internally coherent pattern of reasoning
    # positive confirmation may have a considerable degree of robustness to experience
        - ppl learn value of looking for disconfirming evidence but seek confirmations with no info value
    - Wason card experiment
        - those who turned over q card had confidence increased with uninformative data

KLAYMAN1995::
    # search for evidence
        - positive test strategies (eg. Wason 2-4-6) do not uncover false negatives
        - subjects confident based on inconclusive data
        - pref for extremity (want info on highly likely/unlikely features)
        - pref for tests which better distinguish alternatives (eg. prefer A or B)?
        - bias potential exists only if one fails to appreciate consequences
            - blind spot OK so long as one knows
    # interpretation of evidence
        - ambiguous evidence (vague, open to interpretation)
            - ppl tend to give hyp benefit of doubt, eg. brand loyalty
        - discount disconfirming evidence esp if data believed to be subject to error (Gorman1981)
            - fake news?
        - feature-positive effects
        - overweight confirming and pseudodiagnostic evidence
        - Bayes' law not widely understood
            - ppl believe p(D|H) alone good enough
            - eg. actions taken, not actions not taken
    - motivation to maintain self esteem and others' view of self
        - be accurate vs. belief preference
            - need more evidence to give up existing hyp than if neutral
        - painful to challenge
            - bad to be wrong
            - courage of one's convictions

RABIN1999::
    - ppl who form initial hyp from weak evidence
        - have difficulty correctly interpreting subsequent, better info which contradicts
            - due to propensity to recall strengths of confirming, weaknesses of disconfirming
            - due to tendency to judge confirming evidence as reliable and relevant, disconfirming as opposite
            - due to accepting confirming evidence at face value and scrutinizing disconfirming evidence hypercritically
    - contributions:
        # interpret ambigious evidence (unlike visual tasks) => CB and overconfidence
            - need degree of abstraction
            - eg. teacher interpreting student as having creative or stupid answers
        # when ppl must interpret statistical evidence for correlation
            - ppl often imagine correlation between events if no correlation exists (eg. sugar => hyperactivity)
            - ppl underestimate correlation if hold no existing theory
                - and exaggerate correlation if preconceived theory
        # when ppl selectively collect or scrutinize evidence
            - ppl tend to ask questions likely to be true if theory is true
              without considering if likely to be true even if hyp is false

NELSON2013::
    - may take only one observation of a difference to add a new "essential" characteristic to a group
    - drive to essentialize to strong that
      generic statements => universal, individual memmbers of class [Khemlani 2009]
    - misinterpretation of stats results somewhat due to tendency to [Bakan 1966]
        - go from sample results in sample aggregate to inferences on population aggregate (Fisherian unfoundedness)o               - eg. "X are more Y than Z" from "statistically significant difference in mean Y"
    - scientific fields not immune:
        eg. Moss-Racusin 2012
            science faculty rated identical applications differently according to sex of applicant

NICKERSON1998::
    # restrict attention of favored hypothesis (even if other opposing beliefs known)
        - p(D|H) vs. p(D|~H)
        - ppl do not consider pseudodiagnosticity
    # preferential treatment of evidence supporting hypothesis
        - give greater weight to favoured hyp
        - fail to recall or produce reasons for competing side
        - have belief as we can think of/recall more reasons to support
        - more likely to rate one-sided arguments higher than two-sided arguments
    # seeking only or mostly positive cases
        - find patterns where they are not
        - selective testing
            - test hyp on examples as if hyp already correct
            - no discovery
            - eg. Wason 2-4-6
            - tie into test cases written after code?
            - tend to ask questions whose answer is yes if hyp true
                - eg. extrovert/introvert
    # seeing what one is looking for
        - askers see answers supportive of hyp
        - answerers influenced by interviewer
        - expectation guided change vs. expectation-interpreted belief
            - eg. low/high-class student with identical tape
        - seeing or remembering expected behaviour
        - belief that 2 vars related
            => increase chances of locating confirming evidence
            => decrease chancees of locating disconfirming evidence
            - illusory correlation
    # overweighing positive confirmatory instances
        - ppl generally require less hyp-consistent evidence to accept
          than hyp-inconsistent evidence to reject
        - depends on degree of confidence and importance of drawing correct conclusion
        - FACTORS: needs for self esteem, control, and cognitive consistency
        # selective attention to what is true, ignore/discount what is not
        # consider only P(D|H), not P(D|~H) (eg. gamblers explain away losses)
        - people fail to apply contrapositive
        - ppl believe P=>Q ~ Q=>P or ~ iff P=>
        - ppl check if consequent is true when antecedent is true
    # primacy effect - info acquired early carries more weight
        - eg. blurry slides of Bruner 1964
        - ppl more likely to question info conflicting pre-existing belief
          than info consistent with pre-existing belief
        - ppl more likely to see ambiguous info as confirming hyp than disconfirming it
            => 2 ppl can see opposing opinion in same info
            - and explain away events inconsistent with prior belief
        - ppl find it easy to stick with beliefs formed with faluse info even after info shown to be false [ROSS82]
            - fake news

LARRICK2004::
    - ppl have basic stats/logic/econ knowledge but may not know how and when to apply
    - ppl reason more accurately about frequency than probability
        - eg. Bayes


Why it develops (signals)
=========================

- tendency to misinterpret new info as supporting prior belief
    - may lead to erroneously interpreting next signal as supporting

KLAYMAN1995::
    - self-perception affected more by actions taken, not actions not taken

RABIN1999::
    - agent may come to believe with near certainty in false hypothesis
      despite receiving and infinite amount of info

    - infinite signals and no confirmatory bias => always correct hypothesis
    - if CB w incorrect hypothesis => bias inhibits ability to overturn erroneous beliefs
        - if strong: agent forever believes very strongly in false hypothesis
        - if severe: learning can exacerbate the bias
    - if convinced, may stop paying attention to additional info
        - cognitive search model
        - process -> strong belief?
            - if yes, stop
            - if no, continue processing

    - belief formation:
        # Start w 50/50 belief hypothesis, no CB
        # Receive a signal of true state of world (assume independent and identically distributed)
            - rational: update belief hyp using Bayes' Rule
            - CB: agent may misinterpret signals which conflict with current belief hyp
                - alt: agent overlooks evidence conflicting with belief, ignores counterhyp evidence
                - CB: perceived signals not independently nor identically distributed
            - severity of bias:
                - if 0, correctly perceives signal
                - if severe, first piece of info completely determines final belief
                    - so rational observer of agents needs order and prior belief
            - effect depends on signal order and prior belief
                - overconfident - prob of belief given # signals pro or con compared with prob of alt hyp
                - underconfident - less than rational, more pro signals
                - Bayesian observer needs agent's initial belief and order of signals to determine degree of CB
                    eg. agent recently changed hyp => underconfident
                - info about order of agent's signals would significantly
                  influence observer's judgment and degree of direction of
                  agent's bias

    - after infinite # of signals:
        - fully Bayesian (no bias) => near certainty, correct hyp
        - assume equal # of pro/con signals and 50/50 start
            - agent may become certain that incorrect hyp is true if bias
              severe OR if bias is slight and signals weak
                => more and more confident in false belief
                => take risky and extreme actions (bad choices)
            - OR may be certain of correct hyp
        - learning may not help false belief

NELSON2015::
    - feels natural => feels incontestable => drawn to confirming

NICKERSON1998::
    - no stance => take a position => defend/justify position
        - justify: with bias, feedback loop
            - assume hyp is true
    - defend with supported info and selective interpretation (and give it weight)
    - AND do not seek and maybe avoid counter-indicative data/alt. possibilities (and lessen its weight)

    - belief that 2 vars related
        => increase chances of locating confirming evidence
        => decrease chances of locating disconfirming evidence
    - illusory correlation
        - also with higher correlation
        - stereotyping
            - specific behaviours more common with some groups
            - unusual behaviour in distinct groups more readily recalled

KLAYMAN1995::
    - decision-making is complex
    - too many vars w competing strategies
    - cost of false negative vs false positive
    - likelihood of failure?
    - sense of importance of vars required
    - CB not unitary but property of complex process of hyp development
        => more than one way to fight it


How to fight back
=================

JONES2000::
    - Wason card
        - subjects almost always recognized significance of disconfirmation if found
        - subjects rarely made deductively incorrect judgements
        - learning increases frequency of optimal response, <p, not q> most stable 21/27
            - but no decline in positive confimation response (q card)

KLAYMAN1995::
    - When does CB go away?
        - possibility of punishment for suboptimal decisions (tie into desire to be right)
        - environment provides opportunity for correction and adjustments
        - depends on strategy paired with environment
            eg. if false positive errors more costly (usually)
                OF if false negatives more costly
            - positive testing
            - need to adapt and people can if there's a cost

    - knowledge and experience
        - context and content
            - eg. selection task and deontic reasoning
            - abstract vs. rule breaking
            - helps most if problem in area of experience
                eg. problems solves frequently (CB absent) vs. unfamiliar domains (bias reappears)
            - AND ppl can tap into a general schema to find inconsistencies
                eg. permission schema and compliance
            - can training help?
                - yes, but needs to be thorough as brief instructions do not help much
                - unclear how specific training must be
                    - and how generalizable they can be

    - consider alternatives
        - ppl do better with 2 alternates than evaluating a single hyp
        - mention of specific alts 3x more common if successful subjects than unsuccessful ones
        - consider alts broadens domain and evaluation need not start anew
        - training and real world knowledge can help
            - natural sets of competing hyps known
            - and distinguising feathres get more attention
            - so facilitates comparisons with info => less pseudodiagnostic errors
        - OR use others to gen alts (like journal reviewers)
            - some studies show better hyp development if alts made explicit
                - OR when asked either/or questions
        - OR discovery
        - difficult to consider >1 hyp at once
            - ppl may think about alts seperately and independently
            - may not seriously consider alts
                - esp if already have viable hyp

RABIN1999::
    - more info likely not better
    - Providing same ambiguous info to ppl differing in beliefs can move beliefs further apart
        eg. inner city child and reading
    - to overcome, incentives to collect more info may not pan out
        - so, mute incentives relative to optimal (and no reward for info gathering)
            eg. investment agent offered constant wage

NELSON2015::
    - bias persists
    - belief as objective => more likely to have confidence in stereotype beliefs and act on them
    - working against stereotype takes more time, uses other areas of brain
        - eg. Francis Bacon quote
    - need wider community of scholars, more diversity of thought and perspective
        - eg. gender, race, class, nationality
        - to reduce locally-held beliefs

NICKERSON1998::
    - ppl often do not consider p(D|~H)
    - ppl are capable of creating reasons for opposing view if explicitly asked to do so
        - motivational problem, not cognitive limitation
    - ppl more likely to rate one-sided arguments higher than two-sided ones
    - same evidence interpreted differently depending on viewpoint
        - and judged as more consistent than reality

LARRICK2004::
    (more notes on paper)
    # do better because…motivation
    # replace imperfect strategies with those which approach normative standards
        eg. prescriptive decision-making
            - can approximate normative ideal but can be readily remembered and implemented
                - meliorists - reasoning falls short but education and experience can improve
                - apologists - normative standards unavailable, intuitive strategies well-adapted
            - always subset of ppl who give normative response on task
                - some can do it, so not unattainable
    - technologist: expand strategies to include external techniques (tools)
        - groups not individuals
        - decision aids and info displays
        - formal decision analysis
        - statistical models
        - lone individuals cannot debias selves
            - some biases not easily recognized and corrected
            - will often not realise use of poor decision-making process
                - delay in feedback on decision
                - existence and source of error difficult to identify

        - no guarantee that standard econ and stats curricula provide best means for improving intuition

    - little evidence that incentives improve decision-making
        - idea assumes ppl must possess effective strategies and fail to
          apply or apply poorly in absence of incentives
            - effective strategies are complicated (Bayes)
                OR simple but require correct strategy applied at correct time
        - BUT incentives may work if task is boring leading to lack of effort
            => superficial process

    # accountability for decisions (similar to incentives but with social benefits)
        - embarrassment, impression
        - pre-emptive self-criticism (anticipate flaws)
        - primarily improves performance on tasks for which ppl already possess appropriate strategy
        - leads to greater effort and use fo info => may result in improved performance
        - "lost pilot" if cues unreliable
        - diff with incentives: strong social need for consistency
            - though detrimental, improves prediction when weighing unreliable cues
        - problems
           - "give ppl what they want"
           - if unknown preference, pre-emptive self-criticism

    # consider the opposite
        - how might I be wrong and why? what reasons?
        - effective at reducing overconfidence, hindsight biases, and anchoring effects
        - consider alt hypothesis shown to reduce CB in seeking and evaluating new info
        - also directs attention to contrary evidence
            - BUT requiring too many contrary reasons => can't, so initial hyp correct

    # training in rules (eg. econ, stats)
        - ppl have basic stats, logic, econ knowledge (like sampling)
            BUT may not know how to apply and when
        - short training sessions in comfortable domain (eg. sports)
            - rule generalized to other domains, but diminished over 2 weeks
        - BEST - combine with abstract and concrete examples
            - makes use automatic
        - BUT complex rules like Bayes' a poor candidate - CB

    # training in representation
        - ppl reason more accurately about frequency than probability
            - SO present info as frequencies
            - OR/AND train ppl to translate prop reasoning into frequency reasoning
            - for conditional probability or Bayes'
                - freq training effective and durable

    # training in biases
        - teach inconsistencies in human reasoning
            - with no instructions to overcome except BEWARE
        - but no controlled experiment with or without recognition skills and decision tools

    # tech strategies
        - out of realm of individual biases
        - group decision-making
            - ppl unknowingly influenced by others judgements => anchor on judgements of others
            - BUT error checking
                - complementary expertise
                - increase sample size of experience
                    - beware shared errors and blid spots
            - diversity of experience, training preserve diversity of perspectives
                - AND formulate own hyp, judgement, estimates independently before group meeting
        - linear models, multi-attribute analysis, decision analysis
            - decompose complex problem into simple problems (eg. pro/con)
        - decision support systems
        - BUT adoption
            - beware top-down, domain-general
            - bottom-up = sense of ownership
            - BUT self-imposed: ppl underestimate bias, are overconfident in their decision-making
                - fail to recognize needing help
        - approaches encourage ppl to think more deeply otherwise
        - linear models
